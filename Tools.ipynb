{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba26349-d1d4-47a9-b923-c8f48b980cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# find geometry intersections within the same dataset using geopandas\n",
    "def find_intersections(gdf: gpd.GeoDataFrame):\n",
    "    # Save geometries to another field\n",
    "    gdf['geom'] = gdf.geometry\n",
    "\n",
    "    # Self join\n",
    "    sj = gpd.sjoin(gdf, gdf,\n",
    "                   how=\"inner\",\n",
    "                   predicate=\"intersects\",\n",
    "                   lsuffix=\"left\",\n",
    "                   rsuffix=\"right\")\n",
    "\n",
    "    # Remove geometries that intersect themselves\n",
    "    sj = sj[sj.index != sj.index_right]\n",
    "\n",
    "    # Extract the intersecting geometry\n",
    "    sj['intersection_geom'] = sj['geom_left'].intersection(sj['geom_right'])\n",
    "\n",
    "    # Reset the geometry (remember to set the CRS correctly!)\n",
    "    sj.set_geometry('intersection_geom', drop=True, inplace=True, crs=gdf.crs)\n",
    "\n",
    "    # Drop duplicate geometries\n",
    "    final_gdf = sj.drop_duplicates(subset=['geometry']).reset_index()\n",
    "\n",
    "    # Drop intermediate fields\n",
    "    drops = ['geom_left', 'geom_right', 'index_right', 'index']\n",
    "    final_gdf = final_gdf.drop(drops, axis=1)\n",
    "\n",
    "    return final_gdf\n",
    "\n",
    "\n",
    "vector_file = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Richland_roads.gpkg\"\n",
    "gdf = gpd.read_file(vector_file)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80899aa9-6322-4a47-b968-481c29397e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gdf = find_intersections(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e047967-84b1-40aa-9ce0-de1fa3fb23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gdf.to_file(r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Richland_roads_intersection.gpkg', layer=\"intersection\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f54354-dba3-41fc-9ef8-0aba26a171fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inter_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d75aee-d3fc-4a38-83bf-0fadb96b55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_6569_gdf = inter_gdf.to_crs(6569)\n",
    "inter_6569_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685acb5-3935-4171-9a52-4a77b65fd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter_6569_gdf.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390dae9-64fa-4dd6-a3c0-b454a8ad3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def buffer_and_dissolve_gdf(gdf, buffer_distance, group_by=None):\n",
    "    \"\"\"\n",
    "    Buffer a point GeoDataFrame and dissolve the resulting buffers.\n",
    "\n",
    "    Parameters:\n",
    "        gdf (gpd.GeoDataFrame): Input GeoDataFrame with point geometries.\n",
    "        buffer_distance (float): The buffer distance in the same units as the GeoDataFrame's CRS.\n",
    "        group_by (str, optional): Column name to group buffers by for dissolving.\n",
    "                                  If None, all buffers are dissolved into a single geometry.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: A GeoDataFrame with the dissolved buffers.\n",
    "    \"\"\"\n",
    "    # Ensure the GeoDataFrame contains point geometries\n",
    "    # if not all(gdf.geometry.type.isin(['Point', 'MultiPoint'])):\n",
    "        # raise ValueError(\"Input GeoDataFrame must contain point geometries.\")\n",
    "\n",
    "    # Apply the buffer\n",
    "    gdf[\"geometry\"] = gdf.geometry.buffer(buffer_distance)\n",
    "\n",
    "    # Dissolve buffers\n",
    "    if group_by:\n",
    "        dissolved_gdf = gdf.dissolve(by=group_by).explode()\n",
    "    else:\n",
    "        dissolved_gdf = gdf.dissolve().explode()\n",
    "\n",
    "    return dissolved_gdf\n",
    "\n",
    "\n",
    "buffered_gdf = buffer_and_dissolve_gdf(inter_6569_gdf, buffer_distance=30)\n",
    "buffered_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a881d-b1ae-4d60-b15d-cc6e8ade2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffered_gdf.explode()\n",
    "buffered_gdf.to_file(r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Richland_roads_intersection_buffer.gpkg', layer=\"intersection\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7076f-5b57-4c17-b8b8-9b27eb617ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_gdf.explore() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6461d-15e4-47fe-97b8-3d78c6fef5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlad Epicollection photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cb008f-0e92-4f58-a197-363addfee621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyepicollect\n",
      "  Downloading pyepicollect-5.1.1.tar.gz (5.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in e:\\programdata\\anaconda3\\envs\\street_mapping_env\\lib\\site-packages (from pyepicollect) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\programdata\\anaconda3\\envs\\street_mapping_env\\lib\\site-packages (from requests->pyepicollect) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\programdata\\anaconda3\\envs\\street_mapping_env\\lib\\site-packages (from requests->pyepicollect) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\programdata\\anaconda3\\envs\\street_mapping_env\\lib\\site-packages (from requests->pyepicollect) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\programdata\\anaconda3\\envs\\street_mapping_env\\lib\\site-packages (from requests->pyepicollect) (2022.12.7)\n",
      "Building wheels for collected packages: pyepicollect\n",
      "  Building wheel for pyepicollect (setup.py): started\n",
      "  Building wheel for pyepicollect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyepicollect: filename=pyepicollect-5.1.1-py3-none-any.whl size=6575 sha256=ce4cb9172ccc05ea492ac9a8a3592a7fe2f3961d04281794118b4dd121bf907a\n",
      "  Stored in directory: c:\\users\\n\\appdata\\local\\pip\\cache\\wheels\\1b\\2b\\84\\61623e3c09ca89c2b0aa160426feb16e59ded8bf3c5d372b62\n",
      "Successfully built pyepicollect\n",
      "Installing collected packages: pyepicollect\n",
      "Successfully installed pyepicollect-5.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of arcgis: .* suffix can only be used with `==` or `!=` operators\n",
      "    keyring (<=21.8.*,>=19)\n",
      "             ~~~~~~~^\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pyepicollect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dda0cf-1131-4c30-9ccf-57354102b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the path to your CSV file\n",
    "csv_file_path = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Heyward_St_ground_truth\\form-1__tree.csv\"\n",
    "\n",
    "# Define the directory where images will be saved\n",
    "output_directory = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Heyward_St_ground_truth\\photos\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Define the base URL of the endpoint\n",
    "base_url = \"https://five.epicollect.net/api/internal/media/tree-diameter-measurement?type=photo&format=entry_original&name=\"\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Extract the image basenames from the column \"5_Photo\"\n",
    "image_basenames = df[\"5_Photo\"]\n",
    "\n",
    "# Function to download an image from the constructed URL\n",
    "def download_image(image_basename):\n",
    "    # Construct the full image URL\n",
    "    image_url = base_url + image_basename\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        print(image_url)\n",
    "        print(response)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        print(response)\n",
    "        # Save the image\n",
    "        image_path = os.path.join(output_directory, image_basename)\n",
    "        with open(image_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {image_basename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {image_basename}: {e}\")\n",
    "\n",
    "# Loop through the image basenames and download each image\n",
    "for basename in image_basenames:\n",
    "    download_image(basename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bc227-d8fa-4ac8-9ead-305fcd40e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the endpoint and credentials\n",
    "token_url = 'https://five.epicollect.net/api/oauth/token'\n",
    "client_id = '5672'  # Replace with your actual Client ID\n",
    "client_secret = '4cnBOLLLojRALnOCUB0DTVEk076mS7dvtoPY5TRI'  # Replace with your actual Client Secret\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(token_url, json=params, headers={'Content-Type': 'application/json'})\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the response\n",
    "    token_info = response.json()\n",
    "    access_token = token_info['access_token']\n",
    "    print(f\"Access Token: {access_token}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve token: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1ee18-5c3c-470f-815f-04fe0a789abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the project slug (replace 'ec5-api-test' with your project slug)\n",
    "project_slug = 'tree-diameter-measurement'\n",
    "base_api_url = f'https://five.epicollect.net/api/export/entries/{project_slug}'\n",
    "\n",
    "# Define the media endpoint base\n",
    "media_base_url = f'https://five.epicollect.net/api/export/media/{project_slug}?type=photo&format=entry_original&name='\n",
    "\n",
    "# Define the directory where images will be saved\n",
    "output_directory = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\street_image_mapping\\Heyward_St_ground_truth\\photos\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to download an image given the filename\n",
    "def download_image(image_name):\n",
    "    image_url = media_base_url + image_name\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()\n",
    "        image_path = os.path.join(output_directory, image_name)\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded: {image_name}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {image_name}: {e}\")\n",
    "\n",
    "# Fetch entries from the project\n",
    "def fetch_entries():\n",
    "    try:\n",
    "        response = requests.get(base_api_url, headers={'Content-Type': 'application/vnd.api+json'})\n",
    "        response.raise_for_status()\n",
    "        entries = response.json()['data']['entries']\n",
    "        return entries\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch entries: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main function to get entries and download corresponding images\n",
    "def download_project_images():\n",
    "    entries = fetch_entries()\n",
    "    for entry in entries:\n",
    "        # Assuming the image filename is stored under 'photo', adapt based on actual response\n",
    "        image_name = entry.get('photo')\n",
    "        image_name = \"test.jpg\"\n",
    "        if image_name:\n",
    "            download_image(image_name)\n",
    "        else:\n",
    "            print(f\"No image found for entry {entry['id']}\")\n",
    "\n",
    "# Run the script to download images\n",
    "if __name__ == \"__main__\":\n",
    "    download_project_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
